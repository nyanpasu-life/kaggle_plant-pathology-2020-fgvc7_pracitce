{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (300, 300)\n",
    "\n",
    "IMAGE_PATH = \"./plant-pathology-2020-fgvc7/images/\"\n",
    "TEST_PATH = \"./plant-pathology-2020-fgvc7/test.csv\"\n",
    "TRAIN_PATH = \"./plant-pathology-2020-fgvc7/aug_train.csv\"\n",
    "#SUB_PATH = \"./plant-pathology-2020-fgvc7/sample_submission.csv\"\n",
    "\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "def load_image(image_id):\n",
    "    file_path = image_id + \".jpg\"\n",
    "    image = cv2.imread(IMAGE_PATH + file_path)\n",
    "\n",
    "    # 이미지를 224, 224로 줄이기\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "images = train_data[\"image_id\"].apply(load_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(images)\n",
    "labels = train_data[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.00025\n",
    "K_NUM= 2\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B3\n",
    "efmodel = EfficientNetV2B3(include_top=False, weights='imagenet', input_shape= (IMAGE_SIZE[1], IMAGE_SIZE[0], 3))\n",
    "model = Sequential()\n",
    "model.add(efmodel)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='leaky_relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b3 (Function  (None, 10, 10, 1536)     12930622  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 153600)            0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 153600)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                9830464   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,761,346\n",
      "Trainable params: 22,652,130\n",
      "Non-trainable params: 109,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "365/365 [==============================] - 37s 78ms/step - loss: 0.9064 - accuracy: 0.7783 - val_loss: 0.3254 - val_accuracy: 0.9011 - lr: 2.5000e-04\n",
      "Epoch 2/100\n",
      "365/365 [==============================] - 28s 77ms/step - loss: 0.4700 - accuracy: 0.8586 - val_loss: 0.3257 - val_accuracy: 0.9011 - lr: 2.5000e-04\n",
      "Epoch 3/100\n",
      "365/365 [==============================] - 28s 78ms/step - loss: 0.5084 - accuracy: 0.8682 - val_loss: 0.3552 - val_accuracy: 0.9121 - lr: 2.5000e-04\n",
      "Epoch 4/100\n",
      "365/365 [==============================] - 29s 79ms/step - loss: 0.4186 - accuracy: 0.8943 - val_loss: 0.7809 - val_accuracy: 0.9148 - lr: 2.5000e-04\n",
      "Epoch 5/100\n",
      "365/365 [==============================] - 29s 79ms/step - loss: 0.4950 - accuracy: 0.8813 - val_loss: 0.3809 - val_accuracy: 0.9176 - lr: 2.5000e-04\n",
      "Epoch 6/100\n",
      "365/365 [==============================] - 29s 79ms/step - loss: 0.4092 - accuracy: 0.9019 - val_loss: 0.2223 - val_accuracy: 0.9313 - lr: 2.5000e-04\n",
      "Epoch 7/100\n",
      "365/365 [==============================] - 29s 80ms/step - loss: 0.4270 - accuracy: 0.8936 - val_loss: 0.8422 - val_accuracy: 0.8571 - lr: 2.5000e-04\n",
      "Epoch 8/100\n",
      "365/365 [==============================] - 29s 79ms/step - loss: 0.5976 - accuracy: 0.8723 - val_loss: 0.5405 - val_accuracy: 0.9258 - lr: 2.5000e-04\n",
      "Epoch 9/100\n",
      "365/365 [==============================] - 29s 81ms/step - loss: 0.4898 - accuracy: 0.8936 - val_loss: 0.3929 - val_accuracy: 0.8846 - lr: 2.5000e-04\n",
      "Epoch 10/100\n",
      "365/365 [==============================] - 30s 82ms/step - loss: 0.4085 - accuracy: 0.9060 - val_loss: 0.2833 - val_accuracy: 0.9396 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "365/365 [==============================] - 31s 86ms/step - loss: 0.3575 - accuracy: 0.9218 - val_loss: 0.3229 - val_accuracy: 0.9286 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.3011 - accuracy: 0.9238 - val_loss: 0.3499 - val_accuracy: 0.9258 - lr: 1.2500e-04\n",
      "Epoch 13/100\n",
      "365/365 [==============================] - 40s 109ms/step - loss: 0.2277 - accuracy: 0.9478 - val_loss: 0.3293 - val_accuracy: 0.9203 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "365/365 [==============================] - 39s 105ms/step - loss: 0.1953 - accuracy: 0.9492 - val_loss: 0.2863 - val_accuracy: 0.9505 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "365/365 [==============================] - 29s 80ms/step - loss: 0.1868 - accuracy: 0.9526 - val_loss: 0.1816 - val_accuracy: 0.9478 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "365/365 [==============================] - 30s 82ms/step - loss: 0.2068 - accuracy: 0.9485 - val_loss: 0.4056 - val_accuracy: 0.9203 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.1849 - accuracy: 0.9520 - val_loss: 0.2361 - val_accuracy: 0.9560 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.1571 - accuracy: 0.9609 - val_loss: 0.2641 - val_accuracy: 0.9341 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "365/365 [==============================] - 49s 134ms/step - loss: 0.1812 - accuracy: 0.9526 - val_loss: 0.2063 - val_accuracy: 0.9451 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "365/365 [==============================] - 30s 82ms/step - loss: 0.1876 - accuracy: 0.9547 - val_loss: 0.1926 - val_accuracy: 0.9533 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.1623 - accuracy: 0.9636 - val_loss: 0.1210 - val_accuracy: 0.9725 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.1361 - accuracy: 0.9719 - val_loss: 0.1676 - val_accuracy: 0.9643 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.1183 - accuracy: 0.9712 - val_loss: 0.1966 - val_accuracy: 0.9560 - lr: 6.2500e-05\n",
      "Epoch 24/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.1046 - accuracy: 0.9732 - val_loss: 0.1207 - val_accuracy: 0.9753 - lr: 6.2500e-05\n",
      "Epoch 25/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.1175 - accuracy: 0.9691 - val_loss: 0.1134 - val_accuracy: 0.9588 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "365/365 [==============================] - 31s 86ms/step - loss: 0.1064 - accuracy: 0.9787 - val_loss: 0.2082 - val_accuracy: 0.9505 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "365/365 [==============================] - 31s 86ms/step - loss: 0.1040 - accuracy: 0.9780 - val_loss: 0.1570 - val_accuracy: 0.9753 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.2138 - val_accuracy: 0.9560 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "365/365 [==============================] - 35s 96ms/step - loss: 0.1182 - accuracy: 0.9671 - val_loss: 0.1570 - val_accuracy: 0.9560 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "365/365 [==============================] - 37s 102ms/step - loss: 0.1049 - accuracy: 0.9787 - val_loss: 0.1418 - val_accuracy: 0.9670 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0959 - accuracy: 0.9808 - val_loss: 0.1689 - val_accuracy: 0.9533 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0941 - accuracy: 0.9794 - val_loss: 0.1573 - val_accuracy: 0.9615 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "365/365 [==============================] - 32s 88ms/step - loss: 0.0850 - accuracy: 0.9822 - val_loss: 0.1262 - val_accuracy: 0.9698 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "365/365 [==============================] - 39s 106ms/step - loss: 0.0919 - accuracy: 0.9787 - val_loss: 0.1295 - val_accuracy: 0.9698 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0788 - accuracy: 0.9863 - val_loss: 0.1355 - val_accuracy: 0.9835 - lr: 3.1250e-05\n",
      "Epoch 36/100\n",
      "365/365 [==============================] - 37s 102ms/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.1445 - val_accuracy: 0.9643 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "365/365 [==============================] - 53s 144ms/step - loss: 0.0740 - accuracy: 0.9849 - val_loss: 0.1169 - val_accuracy: 0.9753 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "365/365 [==============================] - 37s 100ms/step - loss: 0.0775 - accuracy: 0.9794 - val_loss: 0.1404 - val_accuracy: 0.9725 - lr: 1.5625e-05\n",
      "Epoch 39/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.0766 - accuracy: 0.9856 - val_loss: 0.1751 - val_accuracy: 0.9643 - lr: 1.5625e-05\n",
      "Epoch 40/100\n",
      "365/365 [==============================] - 33s 90ms/step - loss: 0.0741 - accuracy: 0.9835 - val_loss: 0.1812 - val_accuracy: 0.9615 - lr: 1.5625e-05\n",
      "Epoch 41/100\n",
      "365/365 [==============================] - 37s 102ms/step - loss: 0.0768 - accuracy: 0.9849 - val_loss: 0.1272 - val_accuracy: 0.9615 - lr: 7.8125e-06\n",
      "Epoch 42/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 0.1403 - val_accuracy: 0.9725 - lr: 7.8125e-06\n",
      "Epoch 43/100\n",
      "365/365 [==============================] - 41s 112ms/step - loss: 0.0699 - accuracy: 0.9863 - val_loss: 0.1351 - val_accuracy: 0.9533 - lr: 7.8125e-06\n",
      "Epoch 44/100\n",
      "365/365 [==============================] - 43s 117ms/step - loss: 0.0699 - accuracy: 0.9842 - val_loss: 0.1323 - val_accuracy: 0.9643 - lr: 7.8125e-06\n",
      "Epoch 45/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0757 - accuracy: 0.9856 - val_loss: 0.1629 - val_accuracy: 0.9505 - lr: 7.8125e-06\n",
      "Epoch 46/100\n",
      "365/365 [==============================] - 33s 89ms/step - loss: 0.0666 - accuracy: 0.9835 - val_loss: 0.1273 - val_accuracy: 0.9615 - lr: 3.9063e-06\n",
      "Epoch 47/100\n",
      "365/365 [==============================] - 50s 136ms/step - loss: 0.0787 - accuracy: 0.9835 - val_loss: 0.1173 - val_accuracy: 0.9643 - lr: 3.9063e-06\n",
      "Epoch 48/100\n",
      "365/365 [==============================] - 37s 101ms/step - loss: 0.0686 - accuracy: 0.9815 - val_loss: 0.1362 - val_accuracy: 0.9698 - lr: 3.9063e-06\n",
      "Epoch 49/100\n",
      "365/365 [==============================] - 42s 115ms/step - loss: 0.0637 - accuracy: 0.9925 - val_loss: 0.1062 - val_accuracy: 0.9753 - lr: 3.9063e-06\n",
      "Epoch 50/100\n",
      "365/365 [==============================] - 38s 103ms/step - loss: 0.0658 - accuracy: 0.9808 - val_loss: 0.1219 - val_accuracy: 0.9588 - lr: 3.9063e-06\n",
      "Epoch 51/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.0639 - accuracy: 0.9883 - val_loss: 0.1052 - val_accuracy: 0.9780 - lr: 3.9063e-06\n",
      "Epoch 52/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.0633 - accuracy: 0.9931 - val_loss: 0.1309 - val_accuracy: 0.9615 - lr: 3.9063e-06\n",
      "Epoch 53/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.0627 - accuracy: 0.9870 - val_loss: 0.1190 - val_accuracy: 0.9588 - lr: 3.9063e-06\n",
      "Epoch 54/100\n",
      "365/365 [==============================] - 31s 86ms/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.1308 - val_accuracy: 0.9615 - lr: 3.9063e-06\n",
      "Epoch 55/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.0624 - accuracy: 0.9883 - val_loss: 0.1302 - val_accuracy: 0.9670 - lr: 3.9063e-06\n",
      "Epoch 56/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.0637 - accuracy: 0.9876 - val_loss: 0.1317 - val_accuracy: 0.9670 - lr: 3.9063e-06\n",
      "Epoch 57/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0692 - accuracy: 0.9863 - val_loss: 0.1288 - val_accuracy: 0.9643 - lr: 1.9531e-06\n",
      "Epoch 58/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0639 - accuracy: 0.9870 - val_loss: 0.1354 - val_accuracy: 0.9615 - lr: 1.9531e-06\n",
      "Epoch 59/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0673 - accuracy: 0.9870 - val_loss: 0.1289 - val_accuracy: 0.9643 - lr: 1.9531e-06\n",
      "Epoch 60/100\n",
      "365/365 [==============================] - 32s 89ms/step - loss: 0.0663 - accuracy: 0.9815 - val_loss: 0.1202 - val_accuracy: 0.9698 - lr: 1.9531e-06\n",
      "Epoch 61/100\n",
      "365/365 [==============================] - 46s 126ms/step - loss: 0.0702 - accuracy: 0.9842 - val_loss: 0.1096 - val_accuracy: 0.9725 - lr: 1.9531e-06\n",
      "Epoch 62/100\n",
      "365/365 [==============================] - 32s 87ms/step - loss: 0.0637 - accuracy: 0.9856 - val_loss: 0.1413 - val_accuracy: 0.9643 - lr: 9.7656e-07\n",
      "Epoch 63/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0639 - accuracy: 0.9870 - val_loss: 0.1249 - val_accuracy: 0.9670 - lr: 9.7656e-07\n",
      "Epoch 64/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.0630 - accuracy: 0.9876 - val_loss: 0.1313 - val_accuracy: 0.9643 - lr: 9.7656e-07\n",
      "Epoch 65/100\n",
      "365/365 [==============================] - 39s 107ms/step - loss: 0.0650 - accuracy: 0.9849 - val_loss: 0.1530 - val_accuracy: 0.9643 - lr: 9.7656e-07\n",
      "Epoch 66/100\n",
      "365/365 [==============================] - 40s 110ms/step - loss: 0.0593 - accuracy: 0.9883 - val_loss: 0.1203 - val_accuracy: 0.9698 - lr: 9.7656e-07\n",
      "Epoch 67/100\n",
      "365/365 [==============================] - 50s 135ms/step - loss: 0.0668 - accuracy: 0.9870 - val_loss: 0.1212 - val_accuracy: 0.9698 - lr: 4.8828e-07\n",
      "Epoch 68/100\n",
      "365/365 [==============================] - 49s 134ms/step - loss: 0.0640 - accuracy: 0.9897 - val_loss: 0.1041 - val_accuracy: 0.9753 - lr: 4.8828e-07\n",
      "Epoch 69/100\n",
      "365/365 [==============================] - 41s 111ms/step - loss: 0.0622 - accuracy: 0.9890 - val_loss: 0.1207 - val_accuracy: 0.9670 - lr: 4.8828e-07\n",
      "Epoch 70/100\n",
      "365/365 [==============================] - 59s 163ms/step - loss: 0.0617 - accuracy: 0.9849 - val_loss: 0.1018 - val_accuracy: 0.9725 - lr: 4.8828e-07\n",
      "Epoch 71/100\n",
      "365/365 [==============================] - 51s 138ms/step - loss: 0.0649 - accuracy: 0.9870 - val_loss: 0.1358 - val_accuracy: 0.9643 - lr: 4.8828e-07\n",
      "Epoch 72/100\n",
      "365/365 [==============================] - 53s 144ms/step - loss: 0.0634 - accuracy: 0.9849 - val_loss: 0.1242 - val_accuracy: 0.9725 - lr: 4.8828e-07\n",
      "Epoch 73/100\n",
      "365/365 [==============================] - 50s 136ms/step - loss: 0.0722 - accuracy: 0.9835 - val_loss: 0.1150 - val_accuracy: 0.9753 - lr: 4.8828e-07\n",
      "Epoch 74/100\n",
      "365/365 [==============================] - 35s 95ms/step - loss: 0.0695 - accuracy: 0.9849 - val_loss: 0.0973 - val_accuracy: 0.9835 - lr: 4.8828e-07\n",
      "Epoch 75/100\n",
      "365/365 [==============================] - 29s 80ms/step - loss: 0.0683 - accuracy: 0.9863 - val_loss: 0.1080 - val_accuracy: 0.9698 - lr: 4.8828e-07\n",
      "Epoch 76/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0593 - accuracy: 0.9842 - val_loss: 0.1213 - val_accuracy: 0.9615 - lr: 4.8828e-07\n",
      "Epoch 77/100\n",
      "365/365 [==============================] - 51s 140ms/step - loss: 0.0628 - accuracy: 0.9876 - val_loss: 0.0992 - val_accuracy: 0.9808 - lr: 4.8828e-07\n",
      "Epoch 78/100\n",
      "365/365 [==============================] - 36s 98ms/step - loss: 0.0625 - accuracy: 0.9849 - val_loss: 0.1228 - val_accuracy: 0.9753 - lr: 4.8828e-07\n",
      "Epoch 79/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.0610 - accuracy: 0.9883 - val_loss: 0.1422 - val_accuracy: 0.9698 - lr: 4.8828e-07\n",
      "Epoch 80/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0641 - accuracy: 0.9835 - val_loss: 0.1221 - val_accuracy: 0.9698 - lr: 2.4414e-07\n",
      "Epoch 81/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0658 - accuracy: 0.9856 - val_loss: 0.1238 - val_accuracy: 0.9698 - lr: 2.4414e-07\n",
      "Epoch 82/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0673 - accuracy: 0.9870 - val_loss: 0.1191 - val_accuracy: 0.9725 - lr: 2.4414e-07\n",
      "Epoch 83/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0676 - accuracy: 0.9876 - val_loss: 0.1057 - val_accuracy: 0.9753 - lr: 2.4414e-07\n",
      "Epoch 84/100\n",
      "365/365 [==============================] - 32s 88ms/step - loss: 0.0621 - accuracy: 0.9911 - val_loss: 0.1105 - val_accuracy: 0.9615 - lr: 2.4414e-07\n",
      "Epoch 85/100\n",
      "365/365 [==============================] - 51s 140ms/step - loss: 0.0629 - accuracy: 0.9883 - val_loss: 0.1003 - val_accuracy: 0.9780 - lr: 1.2207e-07\n",
      "Epoch 86/100\n",
      "365/365 [==============================] - 48s 132ms/step - loss: 0.0605 - accuracy: 0.9897 - val_loss: 0.1165 - val_accuracy: 0.9698 - lr: 1.2207e-07\n",
      "Epoch 87/100\n",
      "365/365 [==============================] - 53s 146ms/step - loss: 0.0611 - accuracy: 0.9856 - val_loss: 0.1345 - val_accuracy: 0.9670 - lr: 1.2207e-07\n",
      "Epoch 88/100\n",
      "365/365 [==============================] - 67s 182ms/step - loss: 0.0658 - accuracy: 0.9856 - val_loss: 0.1185 - val_accuracy: 0.9560 - lr: 1.2207e-07\n",
      "Epoch 89/100\n",
      "365/365 [==============================] - 42s 114ms/step - loss: 0.0643 - accuracy: 0.9835 - val_loss: 0.1290 - val_accuracy: 0.9615 - lr: 1.2207e-07\n",
      "Epoch 90/100\n",
      "365/365 [==============================] - 30s 81ms/step - loss: 0.0658 - accuracy: 0.9876 - val_loss: 0.1352 - val_accuracy: 0.9725 - lr: 6.1035e-08\n",
      "Epoch 91/100\n",
      "365/365 [==============================] - 30s 82ms/step - loss: 0.0637 - accuracy: 0.9849 - val_loss: 0.1278 - val_accuracy: 0.9698 - lr: 6.1035e-08\n",
      "Epoch 92/100\n",
      "365/365 [==============================] - 30s 82ms/step - loss: 0.0665 - accuracy: 0.9822 - val_loss: 0.1137 - val_accuracy: 0.9725 - lr: 6.1035e-08\n",
      "Epoch 93/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0595 - accuracy: 0.9911 - val_loss: 0.1175 - val_accuracy: 0.9698 - lr: 6.1035e-08\n",
      "Epoch 94/100\n",
      "365/365 [==============================] - 30s 83ms/step - loss: 0.0641 - accuracy: 0.9876 - val_loss: 0.1286 - val_accuracy: 0.9643 - lr: 6.1035e-08\n",
      "Epoch 95/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0675 - accuracy: 0.9842 - val_loss: 0.1055 - val_accuracy: 0.9753 - lr: 3.0518e-08\n",
      "Epoch 96/100\n",
      "365/365 [==============================] - 32s 88ms/step - loss: 0.0620 - accuracy: 0.9904 - val_loss: 0.1362 - val_accuracy: 0.9725 - lr: 3.0518e-08\n",
      "Epoch 97/100\n",
      "365/365 [==============================] - 46s 125ms/step - loss: 0.0624 - accuracy: 0.9883 - val_loss: 0.1182 - val_accuracy: 0.9808 - lr: 3.0518e-08\n",
      "Epoch 98/100\n",
      "365/365 [==============================] - 31s 84ms/step - loss: 0.0664 - accuracy: 0.9849 - val_loss: 0.1200 - val_accuracy: 0.9588 - lr: 3.0518e-08\n",
      "Epoch 99/100\n",
      "365/365 [==============================] - 31s 83ms/step - loss: 0.0679 - accuracy: 0.9815 - val_loss: 0.1246 - val_accuracy: 0.9615 - lr: 3.0518e-08\n",
      "Epoch 100/100\n",
      "365/365 [==============================] - 31s 85ms/step - loss: 0.0643 - accuracy: 0.9835 - val_loss: 0.1209 - val_accuracy: 0.9698 - lr: 1.5259e-08\n"
     ]
    }
   ],
   "source": [
    "y_categorical = np.argmax(labels, axis=1)\n",
    "k = 5  # Number of folds\n",
    "stratified_kfold = StratifiedKFold(n_splits=k)\n",
    "\n",
    "history = None\n",
    "for i, (train_indices, test_indices) in enumerate(stratified_kfold.split(images, y_categorical)):\n",
    "    if i != K_NUM:\n",
    "        continue\n",
    "        \n",
    "    train_images, val_images = images[train_indices], images[test_indices]\n",
    "    train_labels, val_labels = labels[train_indices], labels[test_indices]\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   rotation_range=5,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=[0.9, 1.1],\n",
    "                                   #brightness_range= [0.7, 1],\n",
    "                                   fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow(x=train_images, y=train_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_generator = train_datagen.flow(x=val_images, y=val_labels, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    modelpath = f'./model/train12/kfold{i}/epoch100.hdf5'\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "    history = model.fit(train_generator, epochs=100, verbose=1, callbacks=[reduce_lr], validation_data=val_generator)\n",
    "    model.save(modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
