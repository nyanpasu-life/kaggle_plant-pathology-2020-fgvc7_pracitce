{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 사이즈 600 x 600으로 증가\n",
    "### 메모리 부족으로 실행 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"./plant-pathology-2020-fgvc7/images/\"\n",
    "\n",
    "IMAGE_PATH = \"./plant-pathology-2020-fgvc7/images/\"\n",
    "TEST_PATH = \"./plant-pathology-2020-fgvc7/test.csv\"\n",
    "TRAIN_PATH = \"./plant-pathology-2020-fgvc7/train.csv\"\n",
    "#SUB_PATH = \"./plant-pathology-2020-fgvc7/sample_submission.csv\"\n",
    "\n",
    "IMAGE_SIZE = (600, 600)\n",
    "\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "def load_image(image_id):\n",
    "    file_path = image_id + \".jpg\"\n",
    "    image = cv2.imread(IMAGE_PATH + file_path)\n",
    "    \n",
    "    # 이미지 크기 확인\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # 이미지 크기가 (2048, 1365)일 경우 회전하여 크기 변경\n",
    "    if height == 2048 and width == 1365:\n",
    "        image = np.rot90(image)\n",
    "\n",
    "    # 이미지를 224, 224로 줄이기\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    return image\n",
    "\n",
    "    #return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "images = train_data[\"image_id\"][:].apply(load_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(images)\n",
    "labels = train_data[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터를 균등하게 분할하여 검증 세트를 생성\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, stratify=labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   rotation_range=5,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "train_generator = train_datagen.flow(x=train_images, y=train_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_generator = train_datagen.flow(x=val_images, y=val_labels, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "\n",
    "efmodel = EfficientNetB7(include_top=False, weights='imagenet', classes=4, input_shape= (IMAGE_SIZE[1], IMAGE_SIZE[0], 3))\n",
    "efmodel.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(efmodel)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3,3), input_shape=(IMAGE_SIZE[1], IMAGE_SIZE[0],3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional)  (None, 19, 19, 2560)     64097687  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 924160)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 924160)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 3696644   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,794,331\n",
      "Trainable params: 67,483,604\n",
      "Non-trainable params: 310,727\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 1.2604 - accuracy: 0.3345\n",
      "Epoch 1: val_loss improved from inf to 1.24320, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 84s 282ms/step - loss: 1.2604 - accuracy: 0.3345 - val_loss: 1.2432 - val_accuracy: 0.3425\n",
      "Epoch 2/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 1.2388 - accuracy: 0.3516\n",
      "Epoch 2: val_loss improved from 1.24320 to 1.21170, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 79s 272ms/step - loss: 1.2388 - accuracy: 0.3516 - val_loss: 1.2117 - val_accuracy: 0.3589\n",
      "Epoch 3/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 1.2181 - accuracy: 0.3956\n",
      "Epoch 3: val_loss did not improve from 1.21170\n",
      "292/292 [==============================] - 79s 270ms/step - loss: 1.2181 - accuracy: 0.3956 - val_loss: 1.2291 - val_accuracy: 0.3616\n",
      "Epoch 4/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 1.0649 - accuracy: 0.5488\n",
      "Epoch 4: val_loss improved from 1.21170 to 0.82772, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 1.0649 - accuracy: 0.5488 - val_loss: 0.8277 - val_accuracy: 0.6685\n",
      "Epoch 5/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.8110 - accuracy: 0.6669\n",
      "Epoch 5: val_loss improved from 0.82772 to 0.79890, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 81s 279ms/step - loss: 0.8110 - accuracy: 0.6669 - val_loss: 0.7989 - val_accuracy: 0.6904\n",
      "Epoch 6/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.6992\n",
      "Epoch 6: val_loss improved from 0.79890 to 0.66902, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 81s 277ms/step - loss: 0.7291 - accuracy: 0.6992 - val_loss: 0.6690 - val_accuracy: 0.7315\n",
      "Epoch 7/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.6755 - accuracy: 0.7253\n",
      "Epoch 7: val_loss improved from 0.66902 to 0.65077, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 79s 271ms/step - loss: 0.6755 - accuracy: 0.7253 - val_loss: 0.6508 - val_accuracy: 0.7260\n",
      "Epoch 8/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.7280\n",
      "Epoch 8: val_loss improved from 0.65077 to 0.64437, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.6506 - accuracy: 0.7280 - val_loss: 0.6444 - val_accuracy: 0.7260\n",
      "Epoch 9/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7624\n",
      "Epoch 9: val_loss improved from 0.64437 to 0.56711, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.6099 - accuracy: 0.7624 - val_loss: 0.5671 - val_accuracy: 0.7397\n",
      "Epoch 10/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.7720\n",
      "Epoch 10: val_loss did not improve from 0.56711\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.5865 - accuracy: 0.7720 - val_loss: 0.5964 - val_accuracy: 0.7534\n",
      "Epoch 11/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7953\n",
      "Epoch 11: val_loss did not improve from 0.56711\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.5574 - accuracy: 0.7953 - val_loss: 0.5712 - val_accuracy: 0.7753\n",
      "Epoch 12/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8022\n",
      "Epoch 12: val_loss improved from 0.56711 to 0.52346, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 83s 282ms/step - loss: 0.5168 - accuracy: 0.8022 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
      "Epoch 13/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.8043\n",
      "Epoch 13: val_loss improved from 0.52346 to 0.48320, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.5277 - accuracy: 0.8043 - val_loss: 0.4832 - val_accuracy: 0.8192\n",
      "Epoch 14/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8276\n",
      "Epoch 14: val_loss did not improve from 0.48320\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.4848 - accuracy: 0.8276 - val_loss: 0.4876 - val_accuracy: 0.8247\n",
      "Epoch 15/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.8310\n",
      "Epoch 15: val_loss did not improve from 0.48320\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.4498 - accuracy: 0.8310 - val_loss: 0.5141 - val_accuracy: 0.8055\n",
      "Epoch 16/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.8407\n",
      "Epoch 16: val_loss improved from 0.48320 to 0.45139, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.4479 - accuracy: 0.8407 - val_loss: 0.4514 - val_accuracy: 0.8301\n",
      "Epoch 17/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8620\n",
      "Epoch 17: val_loss did not improve from 0.45139\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.4172 - accuracy: 0.8620 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
      "Epoch 18/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8681\n",
      "Epoch 18: val_loss did not improve from 0.45139\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.4034 - accuracy: 0.8681 - val_loss: 0.5423 - val_accuracy: 0.8110\n",
      "Epoch 19/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8544\n",
      "Epoch 19: val_loss improved from 0.45139 to 0.37147, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.4315 - accuracy: 0.8544 - val_loss: 0.3715 - val_accuracy: 0.8685\n",
      "Epoch 20/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8571\n",
      "Epoch 20: val_loss did not improve from 0.37147\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.4083 - accuracy: 0.8571 - val_loss: 0.4257 - val_accuracy: 0.8466\n",
      "Epoch 21/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8729\n",
      "Epoch 21: val_loss did not improve from 0.37147\n",
      "292/292 [==============================] - 76s 260ms/step - loss: 0.3621 - accuracy: 0.8729 - val_loss: 0.3963 - val_accuracy: 0.8685\n",
      "Epoch 22/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8757\n",
      "Epoch 22: val_loss did not improve from 0.37147\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.3576 - accuracy: 0.8757 - val_loss: 0.3865 - val_accuracy: 0.8795\n",
      "Epoch 23/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8784\n",
      "Epoch 23: val_loss did not improve from 0.37147\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.3686 - accuracy: 0.8784 - val_loss: 0.3874 - val_accuracy: 0.8767\n",
      "Epoch 24/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8798\n",
      "Epoch 24: val_loss did not improve from 0.37147\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.3649 - accuracy: 0.8798 - val_loss: 0.4274 - val_accuracy: 0.8521\n",
      "Epoch 25/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8812\n",
      "Epoch 25: val_loss improved from 0.37147 to 0.36625, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.3428 - accuracy: 0.8812 - val_loss: 0.3662 - val_accuracy: 0.8849\n",
      "Epoch 26/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8723\n",
      "Epoch 26: val_loss improved from 0.36625 to 0.35939, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.3965 - accuracy: 0.8723 - val_loss: 0.3594 - val_accuracy: 0.8795\n",
      "Epoch 27/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8901\n",
      "Epoch 27: val_loss improved from 0.35939 to 0.32141, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.3383 - accuracy: 0.8901 - val_loss: 0.3214 - val_accuracy: 0.8986\n",
      "Epoch 28/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8839\n",
      "Epoch 28: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 77s 262ms/step - loss: 0.3437 - accuracy: 0.8839 - val_loss: 0.3303 - val_accuracy: 0.9041\n",
      "Epoch 29/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8970\n",
      "Epoch 29: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.3079 - accuracy: 0.8970 - val_loss: 0.3473 - val_accuracy: 0.8986\n",
      "Epoch 30/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8942\n",
      "Epoch 30: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 76s 260ms/step - loss: 0.3298 - accuracy: 0.8942 - val_loss: 0.3410 - val_accuracy: 0.8932\n",
      "Epoch 31/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.8984\n",
      "Epoch 31: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.2973 - accuracy: 0.8984 - val_loss: 0.3435 - val_accuracy: 0.8877\n",
      "Epoch 32/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8963\n",
      "Epoch 32: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 76s 262ms/step - loss: 0.3186 - accuracy: 0.8963 - val_loss: 0.3249 - val_accuracy: 0.8986\n",
      "Epoch 33/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.8874\n",
      "Epoch 33: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 79s 271ms/step - loss: 0.3261 - accuracy: 0.8874 - val_loss: 0.3378 - val_accuracy: 0.8986\n",
      "Epoch 34/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.8977\n",
      "Epoch 34: val_loss did not improve from 0.32141\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2959 - accuracy: 0.8977 - val_loss: 0.4498 - val_accuracy: 0.8603\n",
      "Epoch 35/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.8977\n",
      "Epoch 35: val_loss improved from 0.32141 to 0.31188, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2986 - accuracy: 0.8977 - val_loss: 0.3119 - val_accuracy: 0.8932\n",
      "Epoch 36/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.8935\n",
      "Epoch 36: val_loss did not improve from 0.31188\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.3061 - accuracy: 0.8935 - val_loss: 0.5568 - val_accuracy: 0.8247\n",
      "Epoch 37/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.8970\n",
      "Epoch 37: val_loss improved from 0.31188 to 0.30252, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2865 - accuracy: 0.8970 - val_loss: 0.3025 - val_accuracy: 0.8767\n",
      "Epoch 38/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8942\n",
      "Epoch 38: val_loss did not improve from 0.30252\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2880 - accuracy: 0.8942 - val_loss: 0.3207 - val_accuracy: 0.8822\n",
      "Epoch 39/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.9093\n",
      "Epoch 39: val_loss improved from 0.30252 to 0.27896, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2887 - accuracy: 0.9093 - val_loss: 0.2790 - val_accuracy: 0.9014\n",
      "Epoch 40/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.9066\n",
      "Epoch 40: val_loss did not improve from 0.27896\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2967 - accuracy: 0.9066 - val_loss: 0.3144 - val_accuracy: 0.9041\n",
      "Epoch 41/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.9045\n",
      "Epoch 41: val_loss did not improve from 0.27896\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2900 - accuracy: 0.9045 - val_loss: 0.3116 - val_accuracy: 0.9068\n",
      "Epoch 42/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.9038\n",
      "Epoch 42: val_loss did not improve from 0.27896\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2672 - accuracy: 0.9038 - val_loss: 0.2873 - val_accuracy: 0.9123\n",
      "Epoch 43/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8977\n",
      "Epoch 43: val_loss did not improve from 0.27896\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2941 - accuracy: 0.8977 - val_loss: 0.3619 - val_accuracy: 0.8658\n",
      "Epoch 44/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9038\n",
      "Epoch 44: val_loss did not improve from 0.27896\n",
      "292/292 [==============================] - 78s 265ms/step - loss: 0.2776 - accuracy: 0.9038 - val_loss: 0.3325 - val_accuracy: 0.9068\n",
      "Epoch 45/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9114\n",
      "Epoch 45: val_loss improved from 0.27896 to 0.27642, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2658 - accuracy: 0.9114 - val_loss: 0.2764 - val_accuracy: 0.9178\n",
      "Epoch 46/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9196\n",
      "Epoch 46: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 267ms/step - loss: 0.2484 - accuracy: 0.9196 - val_loss: 0.2766 - val_accuracy: 0.9123\n",
      "Epoch 47/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9025\n",
      "Epoch 47: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 271ms/step - loss: 0.2745 - accuracy: 0.9025 - val_loss: 0.3309 - val_accuracy: 0.8904\n",
      "Epoch 48/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9100\n",
      "Epoch 48: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 268ms/step - loss: 0.2619 - accuracy: 0.9100 - val_loss: 0.3532 - val_accuracy: 0.8795\n",
      "Epoch 49/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9066\n",
      "Epoch 49: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2726 - accuracy: 0.9066 - val_loss: 0.3040 - val_accuracy: 0.9041\n",
      "Epoch 50/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9059\n",
      "Epoch 50: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2751 - accuracy: 0.9059 - val_loss: 0.2769 - val_accuracy: 0.9151\n",
      "Epoch 51/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9100\n",
      "Epoch 51: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 269ms/step - loss: 0.2566 - accuracy: 0.9100 - val_loss: 0.3431 - val_accuracy: 0.8986\n",
      "Epoch 52/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9148\n",
      "Epoch 52: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 269ms/step - loss: 0.2731 - accuracy: 0.9148 - val_loss: 0.3083 - val_accuracy: 0.9151\n",
      "Epoch 53/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9128\n",
      "Epoch 53: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 269ms/step - loss: 0.2492 - accuracy: 0.9128 - val_loss: 0.3587 - val_accuracy: 0.8603\n",
      "Epoch 54/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9032\n",
      "Epoch 54: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2770 - accuracy: 0.9032 - val_loss: 0.2959 - val_accuracy: 0.9068\n",
      "Epoch 55/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9100\n",
      "Epoch 55: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2527 - accuracy: 0.9100 - val_loss: 0.3095 - val_accuracy: 0.8986\n",
      "Epoch 56/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9038\n",
      "Epoch 56: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 267ms/step - loss: 0.2809 - accuracy: 0.9038 - val_loss: 0.3170 - val_accuracy: 0.9041\n",
      "Epoch 57/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9114\n",
      "Epoch 57: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 270ms/step - loss: 0.2632 - accuracy: 0.9114 - val_loss: 0.2805 - val_accuracy: 0.9041\n",
      "Epoch 58/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9107\n",
      "Epoch 58: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 269ms/step - loss: 0.2603 - accuracy: 0.9107 - val_loss: 0.3487 - val_accuracy: 0.8795\n",
      "Epoch 59/10000\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8976\n",
      "Epoch 59: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 78s 268ms/step - loss: 0.2925 - accuracy: 0.8977 - val_loss: 0.3534 - val_accuracy: 0.9014\n",
      "Epoch 60/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.9059\n",
      "Epoch 60: val_loss did not improve from 0.27642\n",
      "292/292 [==============================] - 79s 271ms/step - loss: 0.2654 - accuracy: 0.9059 - val_loss: 0.3182 - val_accuracy: 0.9151\n",
      "Epoch 61/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.9121\n",
      "Epoch 61: val_loss improved from 0.27642 to 0.25568, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 78s 268ms/step - loss: 0.2590 - accuracy: 0.9121 - val_loss: 0.2557 - val_accuracy: 0.9151\n",
      "Epoch 62/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9176\n",
      "Epoch 62: val_loss did not improve from 0.25568\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2563 - accuracy: 0.9176 - val_loss: 0.2869 - val_accuracy: 0.9096\n",
      "Epoch 63/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9025\n",
      "Epoch 63: val_loss did not improve from 0.25568\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2536 - accuracy: 0.9025 - val_loss: 0.2865 - val_accuracy: 0.9151\n",
      "Epoch 64/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9087\n",
      "Epoch 64: val_loss did not improve from 0.25568\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2571 - accuracy: 0.9087 - val_loss: 0.2670 - val_accuracy: 0.9068\n",
      "Epoch 65/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9107\n",
      "Epoch 65: val_loss improved from 0.25568 to 0.23937, saving model to .\\test.hdf5\n",
      "292/292 [==============================] - 133s 457ms/step - loss: 0.2437 - accuracy: 0.9107 - val_loss: 0.2394 - val_accuracy: 0.9260\n",
      "Epoch 66/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9231\n",
      "Epoch 66: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 85s 291ms/step - loss: 0.2272 - accuracy: 0.9231 - val_loss: 0.2897 - val_accuracy: 0.9041\n",
      "Epoch 67/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9210\n",
      "Epoch 67: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 121s 417ms/step - loss: 0.2275 - accuracy: 0.9210 - val_loss: 0.3048 - val_accuracy: 0.9123\n",
      "Epoch 68/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9100\n",
      "Epoch 68: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 77s 264ms/step - loss: 0.2593 - accuracy: 0.9100 - val_loss: 0.2826 - val_accuracy: 0.9123\n",
      "Epoch 69/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.9059\n",
      "Epoch 69: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 76s 259ms/step - loss: 0.2549 - accuracy: 0.9059 - val_loss: 0.2805 - val_accuracy: 0.9014\n",
      "Epoch 70/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9169\n",
      "Epoch 70: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 76s 261ms/step - loss: 0.2342 - accuracy: 0.9169 - val_loss: 0.2617 - val_accuracy: 0.9260\n",
      "Epoch 71/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9279\n",
      "Epoch 71: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 77s 265ms/step - loss: 0.2070 - accuracy: 0.9279 - val_loss: 0.2586 - val_accuracy: 0.9260\n",
      "Epoch 72/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.9093\n",
      "Epoch 72: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2481 - accuracy: 0.9093 - val_loss: 0.3175 - val_accuracy: 0.9041\n",
      "Epoch 73/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9183\n",
      "Epoch 73: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2450 - accuracy: 0.9183 - val_loss: 0.2643 - val_accuracy: 0.9068\n",
      "Epoch 74/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9231\n",
      "Epoch 74: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2212 - accuracy: 0.9231 - val_loss: 0.3693 - val_accuracy: 0.8849\n",
      "Epoch 75/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9272\n",
      "Epoch 75: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 78s 266ms/step - loss: 0.2242 - accuracy: 0.9272 - val_loss: 0.2960 - val_accuracy: 0.9151\n",
      "Epoch 76/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9231\n",
      "Epoch 76: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 78s 267ms/step - loss: 0.2246 - accuracy: 0.9231 - val_loss: 0.3468 - val_accuracy: 0.8959\n",
      "Epoch 77/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9128\n",
      "Epoch 77: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 132s 451ms/step - loss: 0.2626 - accuracy: 0.9128 - val_loss: 0.2396 - val_accuracy: 0.9178\n",
      "Epoch 78/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9251\n",
      "Epoch 78: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 105s 361ms/step - loss: 0.2421 - accuracy: 0.9251 - val_loss: 0.2929 - val_accuracy: 0.8959\n",
      "Epoch 79/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9162\n",
      "Epoch 79: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 80s 275ms/step - loss: 0.2302 - accuracy: 0.9162 - val_loss: 0.3238 - val_accuracy: 0.8932\n",
      "Epoch 80/10000\n",
      "292/292 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9183\n",
      "Epoch 80: val_loss did not improve from 0.23937\n",
      "292/292 [==============================] - 81s 277ms/step - loss: 0.2289 - accuracy: 0.9183 - val_loss: 0.3154 - val_accuracy: 0.9151\n",
      "Epoch 81/10000\n",
      " 82/292 [=======>......................] - ETA: 45s - loss: 0.2101 - accuracy: 0.9244"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1084\\2455829645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mearly_stopping_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\tensorflowenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 및 검증\n",
    "modelpath = './test.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=30)\n",
    "history = model.fit(train_generator, epochs=10000, verbose=1, callbacks=[early_stopping_callback, checkpointer], validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1084\\4261777744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 6 훈련 과정 시각화 (정확도)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# 6 훈련 과정 시각화 (정확도)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 7 훈련 과정 시각화 (손실)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
